{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the decoder and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "import replay_trajectory_classification as rtc\n",
    "import track_linearization as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_filename = \"../../../../datasets/decoder_data/position_info.pkl\"\n",
    "spikes_filename = \"../../../../datasets/decoder_data/clusterless_spike_times.pkl\"\n",
    "features_filename = \"../../../../datasets/decoder_data/clusterless_spike_features.pkl\"\n",
    "model_filename = \"../../../../datasets/decoder_data/clusterless_spike_decoder.pkl\"\n",
    "decoding_filename = \"../../../../datasets/decoder_data/clusterless_spike_decoding_results.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df = pd.read_pickle(positions_filename)\n",
    "timestamps = positions_df.index.to_numpy()\n",
    "time_start = timestamps[0]\n",
    "time_end = timestamps[-1]\n",
    "dt = 0.02\n",
    "Fs = 1.0 / dt\n",
    "spikes_bins = np.arange(time_start - dt, time_end + dt, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = positions_df[\"nose_x\"].to_numpy()\n",
    "y = positions_df[\"nose_y\"].to_numpy()\n",
    "positions = np.column_stack((x, y))\n",
    "node_positions = [(120.0, 100.0),\n",
    "                    (  5.0, 100.0),\n",
    "                    (  5.0,  55.0),\n",
    "                    (120.0,  55.0),\n",
    "                    (  5.0,   8.5),\n",
    "                    (120.0,   8.5),\n",
    "                    ]\n",
    "edges = [\n",
    "            (3, 2),\n",
    "            (0, 1),\n",
    "            (1, 2),\n",
    "            (5, 4),\n",
    "            (4, 2),\n",
    "        ]\n",
    "track_graph = rtc.make_track_graph(node_positions, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_order = [\n",
    "                (3, 2),\n",
    "                (0, 1),\n",
    "                (1, 2),\n",
    "                (5, 4),\n",
    "                (4, 2),\n",
    "                ]\n",
    "\n",
    "edge_spacing = [16, 0, 16, 0]\n",
    "\n",
    "linearized_positions = tl.get_linearized_position(positions, track_graph, edge_order=edge_order, edge_spacing=edge_spacing, use_HMM=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(features_filename, \"rb\") as f:\n",
    "    clusterless_spike_features = pkl.load(f)\n",
    "\n",
    "with open(spikes_filename, \"rb\") as f:\n",
    "    clusterless_spike_times = pkl.load(f)\n",
    "\n",
    "features = np.ones((len(spikes_bins) - 1, len(clusterless_spike_features[0][0]), len(clusterless_spike_times)), dtype=float) * np.nan\n",
    "for n in range(len(clusterless_spike_times)):\n",
    "    in_spikes_window = np.digitize(clusterless_spike_times[n], spikes_bins) - 1\n",
    "    features[in_spikes_window, :, n] = clusterless_spike_features[n]\n",
    "\n",
    "linear_position = np.ones(len(spikes_bins) - 1) * np.nan\n",
    "in_position_window = np.digitize(positions_df.index, spikes_bins) - 1\n",
    "linear_position[in_position_window] = linearized_positions.linear_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_bin_size = 0.5\n",
    "movement_var = 0.25\n",
    "\n",
    "environment = rtc.Environment(place_bin_size=place_bin_size,\n",
    "                                track_graph=track_graph,\n",
    "                                edge_order=edge_order,\n",
    "                                edge_spacing=edge_spacing)\n",
    "\n",
    "transition_type = rtc.RandomWalk(movement_var=movement_var)\n",
    "\n",
    "decoder = rtc.ClusterlessDecoder(\n",
    "    environment=environment,\n",
    "    transition_type=transition_type,\n",
    "    clusterless_algorithm=\"multiunit_likelihood_integer_gpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Learning model parameters\")\n",
    "decoder.fit(linear_position, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving model to {model_filename}\")\n",
    "\n",
    "results = dict(decoder=decoder)\n",
    "\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_start_secs = 0\n",
    "decoding_duration_secs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decoding positions from features\")\n",
    "decoding_start_samples = int(decoding_start_secs * Fs)\n",
    "decoding_duration_samples = int(decoding_duration_secs * Fs)\n",
    "time_ind = slice(decoding_start_samples, decoding_start_samples + decoding_duration_samples)\n",
    "time = np.arange(linear_position.size) / Fs\n",
    "decoding_results = decoder.predict(features[time_ind], time=time[time_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving decoded results to {decoding_filename}\")\n",
    "\n",
    "results = dict(decoding_results=decoding_results,\n",
    "                linear_position=linear_position[time_ind],\n",
    "                spikes=features[time_ind])\n",
    "\n",
    "with open(decoding_filename, \"wb\") as f:\n",
    "    pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional\n",
    "\n",
    "Plot the decoded results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "trace = go.Heatmap(z=decoding_results.acausal_posterior.T,\n",
    "                    x=decoding_results.acausal_posterior.time,\n",
    "                    y=decoding_results.acausal_posterior.position,\n",
    "                    zmin=0.00, zmax=0.05, showscale=False)\n",
    "fig.add_trace(trace)\n",
    "\n",
    "trace = go.Scatter(x=time[time_ind], y=linear_position,\n",
    "                    mode=\"markers\", marker={\"color\": \"cyan\", \"size\": 5},\n",
    "                    name=\"position\", showlegend=True)\n",
    "fig.add_trace(trace)\n",
    "\n",
    "fig.update_xaxes(title=\"Time (sec)\")\n",
    "fig.update_yaxes(title=\"Position (cm)\")\n",
    "fig.update_coloraxes(showscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
